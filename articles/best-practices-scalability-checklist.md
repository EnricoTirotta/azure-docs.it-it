<properties
   pageTitle="Elenco di controllo per la scalabilità | Microsoft Azure"
   description="Indicazioni sull'elenco di controllo per la scalabilità per le problematiche di progettazione relative alla scalabilità automatica di Azure."
   services=""
   documentationCenter="na"
   authors="dragon119"
   manager="masimms"
   editor=""
   tags=""/>

<tags
   ms.service="best-practice"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="na"
   ms.date="04/28/2015"
   ms.author="masashin"/>

# Elenco di controllo per la scalabilità

![](media/best-practices-scalability-checklist/pnp-logo.png)

## Progettazione dei servizi
- **Partizionare il carico di lavoro**. Progettare le diverse parti del processo in modo che siano discrete e scomponibili, riducendo il più possibile la dimensione di ognuna e attenendosi comunque alle regole tipiche di separazione dei compiti e al principio di responsabilità singola. Questo consente di distribuire le parti costitutive in modo da ottimizzare l'uso di ogni unità di calcolo (ad esempio server di database o ruoli) e facilita la scalabilità dell'applicazione mediante l'aggiunta di altre istanze di risorse specifiche. Per altre informazioni, vedere le [indicazioni sul partizionamento delle risorse di calcolo](https://msdn.microsoft.com/library/dn568099.aspx).
- **Progettare per la scalabilità**. La scalabilità consente alle applicazioni di reagire a un carico variabile aumentando o diminuendo il numero di istanze dei ruoli, delle code e di altri servizi usati. L'applicazione deve tuttavia essere progettata tenendo presente tale necessità. Ad esempio, l'applicazione e i servizi da essa usati devono essere senza stato per consentire il routing delle richieste a qualsiasi istanza, in modo che l'aggiunta o la rimozione di istanze specifiche non si ripercuota negativamente sugli utenti correnti. Occorre inoltre implementare la configurazione o il rilevamento automatico delle istanze man mano che vengono aggiunte o rimosse, in maniera tale che il codice nell'applicazione possa eseguire il routing necessario. Ad esempio, un'applicazione Web potrebbe usare un set di code secondo un approccio round robin per instradare le richieste ai servizi in background in esecuzione in ruoli di lavoro. L'applicazione Web deve essere in grado di rilevare le variazioni nel numero di code per poter instradare correttamente le richieste e bilanciare il carico.
- **Scalare come unità**. Durante la pianificazione tenere conto dell'eventualità di aggiungere altre risorse per far fronte a una possibile espansione. Per ogni risorsa, è opportuno conoscere i limiti massimi di scalabilità e usare il partizionamento orizzontale o la scomposizione per oltrepassare tali limiti. Determinare le unità di scala per il sistema in termini di set di risorse ben definiti. In questo modo, l'uso di operazioni di scalabilità orizzontale risulterà più semplice e avrà meno probabilità di incidere negativamente sull'applicazione a seguito delle limitazioni derivanti dalla mancanza di risorse in una determinata area del sistema generale. Ad esempio, se si aggiunge un numero x di ruoli Web e di lavoro, potrebbero essere necessari y code aggiuntive e z account di archiviazione per gestire il carico di lavoro extra generato dai ruoli, pertanto un'unità di scala potrebbe essere costituita da x ruoli Web e di lavoro, _y_ code e _z_ account di archiviazione. Progettare pertanto l'applicazione in modo che possa essere scalata facilmente aggiungendo una o più unità di scala.
- **Evitare l'affinità client**. Ove possibile, assicurarsi che l'applicazione non richieda l'affinità in modo che le richieste possano essere instradate a qualsiasi istanza e che il numero delle istanze sia irrilevante. Questo inoltre evita il sovraccarico dovuto all'archiviazione, al recupero e alla gestione delle informazioni sullo stato per ogni utente.
- **Sfruttare le funzionalità di scalabilità automatica della piattaforma**. Quando la piattaforma di hosting supporta una funzionalità di scalabilità automatica, quale ad esempio la scalabilità automatica di Azure, preferirla a meccanismi personalizzati o di terze parti, a meno che il meccanismo incorporato non sia in grado di soddisfare i requisiti. Ove possibile, usare regole di scalabilità pianificata per garantire la disponibilità delle risorse senza ritardi di avvio, ma aggiungere alle regole una scalabilità automatica reattiva (quando opportuno) per gestire variazioni impreviste della domanda. È possibile usare le operazioni di scalabilità automatica nell'API di gestione del servizio per ottimizzare la scalabilità automatica e aggiungere alle regole contatori personalizzati al di fuori delle opzioni di configurazione disponibili nel portale Web. Per altre informazioni, vedere la pagina relativa alle [indicazioni sulla scalabilità automatica](best-practices-auto-scaling.md).
- **Eseguire l'offload delle attività a elevato utilizzo di CPU/IO come attività in background**. Se si prevede che una richiesta a un servizio comporti una lunga esecuzione o assorba una quantità considerevole di risorse, eseguire l'offload dell'elaborazione relativa alla richiesta in un'attività separata. Usare ruoli di lavoro o processi in background (a seconda della piattaforma di hosting) per eseguire queste attività. Tale strategia consente al servizio di continuare a ricevere altre richieste restando reattivo. Per altre informazioni, vedere le [indicazioni sui processi in background](best-practices-background-jobs.md).
- **Distribuire il carico di lavoro per le attività in background**. Se sono presenti numerose attività in background o se le attività richiedono una notevole quantità di tempo o risorse, suddividere il lavoro tra più unità di calcolo, ad esempio ruoli di lavoro o processi in background. Il [modello con consumer concorrenti](https://msdn.microsoft.com/library/dn568101.aspx) offre una possibile soluzione.
- **Considerare la possibilità di passare a un'architettura _senza condivisione_**. Un'architettura senza condivisione usa nodi indipendenti e autosufficienti che non dispongono di alcun punto di contesa, ad esempio risorse di archiviazione o servizi condivisi. In teoria un sistema di questo tipo può essere scalato quasi all'infinito. Se un approccio totalmente senza condivisione in genere risulta non pratico per la maggior parte delle applicazioni, può offrire opportunità di progettazione per una migliore scalabilità. Ad esempio, il fatto di evitare l'uso dello stato della sessione sul lato server, l'affinità client e il partizionamento dei dati rappresentano buoni esempi di transizione verso un'architettura senza condivisione.

## Gestione dati

- **Usare il partizionamento dei dati**. Suddividere i dati tra più database e server di database oppure progettare l'applicazione per l'uso di servizi di archiviazione dati in grado di fornire tale partizionamento in modo trasparente (la funzionalità di scalabilità elastica del database SQL di Azure e l'archiviazione tabelle di Azure sono solo alcuni esempi). Questo approccio può contribuire a ottimizzare le prestazioni e consente di implementare più facilmente la scalabilità. Sono disponibili diverse tecniche di partizionamento, ad esempio orizzontale, verticale e funzionale, ed è possibile usare una combinazione di esse per ottenere i massimi vantaggi dalle migliori prestazioni delle query, una scalabilità semplificata, una gestione più flessibile e una maggiore disponibilità e per adattare il tipo di archivio ai dati che dovrà contenere. Considerare inoltre l'eventualità di usare tipi diversi di archivio dati per tipi diversi di dati, effettuando la scelta in base al modo in cui sono ottimizzati per il tipo di dati specifico. Questo può includere l'uso dell'archivio tabelle, di un database di documenti o di un archivio dati di famiglie di colonne al posto o insieme a un database relazionale. Per altre informazioni, vedere le [indicazioni sul partizionamento dei dati](best-practices-data-partitioning.md).
- **Progettare ai fini della coerenza finale**. La coerenza finale migliora la scalabilità riducendo o eliminando il tempo necessario per sincronizzare i dati correlati partizionati in più archivi. Lo svantaggio è rappresentato dal fatto che i dati non sono sempre coerenti al momento della lettura e che alcune operazioni di scrittura possono causare conflitti. La coerenza finale è ideale per le situazioni in cui gli stessi dati vengono letti frequentemente, ma scritti raramente. Per altre informazioni, vedere le [indicazioni sulla coerenza dei dati](#insertlink#).
- **Ridurre le interazioni "frammentate" tra componenti e servizi**. Per i servizi evitare di progettare interfacce _"frammentate" o "chatty"_, in cui un'applicazione deve effettuare più chiamate a un servizio (ognuna delle quali restituisce una piccola quantità di dati) invece di una singola chiamata in grado di restituire tutti i dati. Quando possibile, combinare diverse operazioni correlate in un'unica richiesta se la chiamata è relativa a un servizio o componente che presenta una latenza notevole. In questo modo è possibile semplificare il monitoraggio delle prestazioni e ottimizzare operazioni complesse. Ad esempio, usare stored procedure nei database per incapsulare la logica complessa e ridurre il numero di round trip e il blocco delle risorse. 
- **Usare le code per livellare il carico per le operazioni di scrittura dati ad alta velocità**. I picchi nella domanda di un servizio possono sovraccaricare tale servizio e causare una propagazione dei problemi. Per evitare tali situazioni, considerare la possibilità di implementare il [modello di livellamento del carico basato sulle code](https://msdn.microsoft.com/library/dn589783.aspx). Usare una coda che funga da buffer tra un'attività e un servizio richiamato per alleggerire i carichi pesanti a intermittenza che potrebbero altrimenti causare un malfunzionamento del servizio o il timeout dell'attività.
- **Ridurre al minimo il carico dell'archivio dati**. L'archivio dati in genere costituisce un collo di bottiglia per l'elaborazione, è una risorsa costosa e la scalabilità orizzontale può risultare difficoltosa. Dove possibile, rimuovere la logica (ad esempio, l'elaborazione di documenti XML o oggetti JSON) dall'archivio dati ed eseguire l'elaborazione all'interno dell'applicazione. Ad esempio, anziché passare l'XML al database (in formato diverso da una stringa opaca per l'archiviazione), è possibile serializzare o deserializzare l'XML all'interno del livello dell'applicazione e passarlo in un formato nativo dell'archivio dati. È in genere molto più semplice scalare orizzontalmente l'applicazione rispetto all'archivio dati, pertanto è consigliabile tentare di eseguire la maggior parte dell'elaborazione a elevato utilizzo di risorse di calcolo all'interno dell'applicazione.
- **Ridurre al minimo il volume dei dati recuperati**. Recuperare solo i dati necessari specificando le colonne e usando criteri per selezionare le righe. Usare i parametri con valori di tabella e il livello di isolamento appropriato. Usare meccanismi quali gli ETag per evitare di recuperare dati inutilmente.
- **Usare la memorizzazione nella cache in modo aggressivo**. Usare la memorizzazione nella cache laddove possibile per ridurre il carico delle risorse e dei servizi che generano o forniscono dati. La memorizzazione nella cache in genere è adatta per i dati relativamente statici o da ottenere con una notevole elaborazione. La memorizzazione nella cache deve avvenire a tutti i livelli appropriati in ogni livello dell'applicazione, tra cui l'accesso ai dati e la generazione dell'interfaccia utente. Per altre informazioni, vedere le [indicazioni sulla memorizzazione nella cache](best-practices-caching.md).
- **Gestire l'aumento e la conservazione dei dati**. La quantità di dati archiviati da un'applicazione aumenterà nel tempo. Questa crescita genererà un aumento dei costi di archiviazione e della latenza durante l'accesso ai dati, il che influisce negativamente sulle prestazioni e sulla velocità effettiva dell'applicazione. È possibile archiviare periodicamente alcuni dati precedenti a cui non si accede più o spostare i dati a cui si accede raramente in un archivio a lungo termine più conveniente anche se la latenza di accesso è superiore.
- **Ottimizzare gli oggetti di trasferimento dati usando un formato binario efficiente**. Gli oggetti di trasferimento dati passano diverse volte da un livello all'altro di un'applicazione, pertanto riducendone le dimensioni si ridurrà il carico per le risorse e la rete. Cercare tuttavia di trovare il giusto compromesso tra questo vantaggio e il sovraccarico derivante dalla conversione dei dati nel formato richiesto in ogni posizione in cui vengono usati e adottare un formato che garantisca la massima interoperabilità per consentire un facile riutilizzo dei componenti.
- **Impostare il controllo cache**. Progettare e configurare l'applicazione per l'uso della memorizzazione nella cache dell'output o della memorizzazione di segmenti laddove possibile per ridurre al minimo il carico di elaborazione.
- **Abilitare la memorizzazione nella cache sul lato client**. Le applicazioni Web devono abilitare le impostazioni della cache per il contenuto che può essere memorizzato nella cache. La memorizzazione nella cache è disabilitata per impostazione predefinita. Configurare il server in modo che fornisca le intestazioni di controllo cache appropriate per consentire la memorizzazione del contenuto nella cache nei server proxy e nei client.
- **Usare Archiviazione BLOB di Azure e la rete CDN per ridurre il carico dell'applicazione**. Considerare la possibilità di archiviare il contenuto pubblico statico o relativamente statico, come immagini, risorse, script e fogli di stile, in un archivio BLOB. Questo approccio risparmia all'applicazione il carico causato dalla generazione dinamica di tale contenuto per ogni richiesta. Considerare inoltre l'eventualità di usare la rete CDN per memorizzare nella cache tale contenuto e fornirlo ai client. L'uso della rete CDN può migliorare le prestazioni a livello del client perché il contenuto viene distribuito dal data center geograficamente più vicino che contiene una cache CDN. Per altre informazioni, vedere le [indicazioni sulla rete CDN](best-practices-cdn.md).

- **Ottimizzare gli indici e le query SQL**. Alcuni costrutti o istruzioni T-SQL possono influire negativamente sulle prestazioni e tale impatto può essere ridotto ottimizzando il codice in una stored procedure. Ad esempio, invece di convertire i tipi **datetime** in **varchar** prima del confronto con un valore letterale **datetime**, è consigliabile usare funzioni di confronto data/ora. L'assenza di indici appropriati può anche rallentare l'esecuzione delle query. Se si usa un framework ORM (Object/Relational Mapping), comprendere come funziona e come può incidere sulle prestazioni del livello di accesso ai dati. Per altre informazioni, vedere [Ottimizzazione delle query](https://technet.microsoft.com/library/ms176005.aspx).
- **Considerare la possibilità di denormalizzare i dati**. La normalizzazione dei dati consente di evitare la duplicazione e l'incoerenza. La gestione di più indici, la verifica dell'integrità referenziale, l'esecuzione di più accessi a piccoli blocchi di dati e l'unione di tabelle tramite join per riassemblare i dati sono tutte operazioni che generano un sovraccarico che può influire negativamente sulle prestazioni. Valutare se una certa duplicazione e un volume di archiviazione aggiuntivo sono accettabili per ridurre il carico dell'archivio dati. Allo stesso scopo, determinare anche se l'applicazione vera e propria (che in genere sarà più facile da scalare) può essere considerata affidabile nell'assumersi attività come la gestione dell'integrità referenziale. Per altre informazioni, vedere le [indicazioni sul partizionamento dei dati](https://github.com/mspnp/azure-guidance/blob/master/Data%20partitioning.md).

## Implementazione dei servizi
- **Usare chiamate asincrone**. Quando possibile, usare codice asincrono per accedere a risorse o servizi che possono essere limitati da larghezza di banda di rete o I/O oppure che hanno una latenza considerevole per evitare di bloccare il thread chiamante. Usare il modello asincrono basato sulle attività per implementare le operazioni asincrone. Per altre informazioni, vedere la pagina relativa al [modello asincrono basato sulle attività](https://msdn.microsoft.com/library/hh873175.aspx) nel sito Web Microsoft.
- **Evitare di bloccare le risorse e usare invece un approccio ottimistico**. Non bloccare mai l'accesso alle risorse, ad esempio di archiviazione o altri servizi che presentino una latenza notevole, perché è una delle cause principali della riduzione delle prestazioni. Usare sempre approcci ottimistici per la gestione delle operazioni simultanee, ad esempio la scrittura in un archivio, e ricorrere alle funzionalità del livello di archiviazione per gestire i conflitti. Nelle applicazioni distribuite i dati possono essere coerenti solo alla fine.
- **Comprimere i dati altamente comprimibili su reti a bassa larghezza di banda e latenza elevata**. Nella maggior parte dei casi, in un'applicazione Web il volume di dati più significativo generato dall'applicazione e passato attraverso la rete è costituito dalle risposte HTTP alle richieste client. La compressione HTTP può ridurre considerevolmente tale volume, soprattutto per il contenuto statico. Questa soluzione può garantire una riduzione dei costi, nonché una diminuzione del carico sulla rete, anche se la compressione del contenuto dinamico applica un carico leggermente più elevato sul server. In altri ambienti più generalizzati la compressione dati può ridurre il volume dei dati trasmessi allo scopo di ridurre al minimo i tempi e costi di trasferimento, ma comporta un sovraccarico per i processi di compressione e decompressione. Deve pertanto essere usata solo quando si ottiene un miglioramento dimostrabile delle prestazioni. Altri metodi di serializzazione, come la codifica binaria o JSON, possono ridurre le dimensioni del payload e allo stesso tempo generare un impatto più limitato sulle prestazioni, mentre è probabile che l'XML ne causi l'aumento.
- **Ridurre al minimo il tempo di utilizzo delle connessioni e delle risorse**. Mantenere le connessioni e le risorse soltanto per il tempo necessario a usarle. Ad esempio, aprire le connessioni solo all'ultimo momento e restituirle al pool di connessioni appena possibile. Acquisire le risorse il più tardi possibile ed eliminarle il prima possibile.
- **Ridurre al minimo il numero di connessioni necessarie**. Le connessioni ai servizi assorbono risorse. Ove possibile, limitare il numero di connessioni necessarie e assicurarsi che le connessioni esistenti vengano riutilizzate quando opportuno. Ad esempio, dopo l'autenticazione, usare la rappresentazione se appropriato per eseguire codice come un'identità specifica. Questo consente un uso ottimale del pool di connessioni mediante il riutilizzo delle stesse. 

	> [AZURE.NOTE]\: * * API per alcuni servizi riutilizza automaticamente le connessioni fornite e sono seguite le linee guida specifiche del servizio. È importante comprendere le condizioni che consentono di riutilizzare la connessione per ogni servizio utilizzato dall'applicazione.
- **Inviare le richieste in batch per ottimizzare l'uso della rete**. Ad esempio, inviare e leggere i messaggi in batch quando si accede a una coda ed eseguire più operazioni di lettura o scrittura come batch durante l'accesso all'archiviazione o a una cache. Questo consente di massimizzare l'efficienza dei servizi e degli archivi dati riducendo il numero di chiamate sulla rete.
- **Evitare l'archiviazione dello stato della sessione sul lato server come requisito** laddove possibile. La gestione dello stato della sessione sul lato server richiede in genere l'affinità client, ovvero il routing di ogni richiesta alla stessa istanza del server, il che incide sulla possibilità di scalare il sistema. Idealmente è consigliabile progettare i client in modo che siano senza stato rispetto ai server usati. Se però l'applicazione deve mantenere lo stato della sessione, archiviare i dati riservati o i grandi volumi di dati per client in una cache del lato server distribuita a cui possano accedere tutte le istanze dell'applicazione.
- **Ottimizzare gli schemi di archiviazione tabelle**. Quando si usano archivi tabelle, come quello di Azure, che richiedono il passaggio e l'elaborazione dei nomi di tabelle e colonne con ogni query, considerare la possibilità di usare nomi più brevi per ridurre tale sovraccarico. Non sacrificare tuttavia la leggibilità o la gestibilità usando nomi compatti non intuitivi.
- **Sfruttare la libreria TPL per eseguire operazioni asincrone**. La libreria TPL (Task Parallel Library) semplifica la scrittura di codice asincrono in grado di eseguire operazioni di I/O. Utilizzare _ConfigureAwait(false)_ laddove possibile per eliminare la dipendenza di una continuazione da un contesto di sincronizzazione specifico e ridurre la possibilità che si verifichino deadlock del thread.
- **Creare dipendenze delle risorse durante la distribuzione o all'avvio dell'applicazione**. Evitare chiamate ripetute ai metodi che verificano l'esistenza di una risorsa e quindi creano la risorsa se questa non esiste (i metodi come _CloudTable.CreateIfNotExists_ e _CloudQueue.CreateIfNotExists_ nella libreria client di Archiviazione di Azure seguono questo modello). Tali metodi possono generare un notevole sovraccarico se vengono richiamati prima di ogni accesso a una tabella o coda di archiviazione. Creare invece le risorse necessarie quando l'applicazione viene distribuita o viene avviata per la prima volta (è accettabile avere una singola chiamata a _CreateIfNotExists_ per ogni risorsa nel codice di avvio per un ruolo Web o di lavoro). Assicurarsi tuttavia di gestire le eccezioni che possono venire generate se il codice tenta di accedere a una risorsa inesistente. In queste situazioni è consigliabile registrare l'eccezione e avvisare l'operatore della mancanza di una risorsa. In alcune circostanze può essere opportuno creare la risorsa mancante come parte del codice di gestione delle eccezioni, ma è consigliabile adottare questo approccio con cautela perché l'assenza della risorsa potrebbe essere indicativa di un errore di programmazione (ad esempio, un nome di risorsa non scritto correttamente) o di un altro problema a livello di infrastruttura.
- **Usare framework semplificati**. Scegliere con attenzione le API e i framework da usare per ridurre al minimo l'utilizzo delle risorse, il tempo di esecuzione e il carico complessivo dell'applicazione. Ad esempio, l'uso dell'API Web per gestire le richieste ai servizi consente di ridurre il footprint dell'applicazione e aumentare la velocità di esecuzione, ma potrebbe non essere adatto per scenari avanzati in cui sono necessarie le funzionalità aggiuntive di WCF.
- **Considerare la possibilità di ridurre al minimo il numero degli account del servizio**. Ad esempio, usare un account specifico per accedere alle risorse o ai servizi che impongono un limite per le connessioni o che vengono eseguiti in modo più efficiente dove vengono mantenute meno connessioni. Questo approccio è comune per i servizi, come ad esempio i database, ma può compromettere la possibilità di controllare accuratamente le operazioni a causa della rappresentazione dell'utente originale.
- **Effettuare la profilatura delle prestazioni e il testing del carico** durante lo sviluppo come parte delle routine di test e prima del rilascio della versione finale per assicurarsi che l'applicazione venga eseguita e scalata come richiesto. Questo testing deve essere eseguito sullo stesso tipo di hardware disponibile nella piattaforma di produzione e con gli stessi tipi e quantità di dati e carico utente che si riscontreranno in produzione. Per altre informazioni, vedere la pagina [Test delle prestazioni di un servizio cloud](https://msdn.microsoft.com/library/azure/hh369930.aspx) nel sito Web Microsoft.

<!---HONumber=Oct15_HO3-->